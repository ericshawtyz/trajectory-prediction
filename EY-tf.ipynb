{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eacRAvueg6g"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBqJJ76eatwh"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Activation, Bidirectional, Dense, Dropout, LSTM, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9ASjWCxelTp"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bMVUcAggqsHM"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data_train.csv', index_col=0)\n",
    "df_test = pd.read_csv('data_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOSy1hElepJp"
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rJ73qHuckBY"
   },
   "outputs": [],
   "source": [
    "X_MIN = 3750901.5068\n",
    "X_MAX = 3770901.5068\n",
    "Y_MIN = -19268905.6133\n",
    "Y_MAX = -19208905.6133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v2MUfni8JB7c"
   },
   "outputs": [],
   "source": [
    "def get_target_value(df, col1='x', col2='y'):\n",
    "    for idx in range(len(df)):\n",
    "        if df.at[idx, col1] >= X_MIN and df.at[idx, col1] <= X_MAX and df.at[idx, col2] >= Y_MIN and df.at[idx, col2] <= Y_MAX:\n",
    "            df.at[idx, 'target'] = 1\n",
    "        else:\n",
    "            df.at[idx, 'target'] = 0\n",
    "    return df['target'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJql2z4SeuIh"
   },
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62K7GErY-llF"
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.drop(['vmax', 'vmin', 'vmean'], axis=1)\n",
    "\n",
    "    df_entry = df[['hash', 'trajectory_id', 'time_entry', 'x_entry', 'y_entry']].copy()\n",
    "#     df_entry['is_exit'] = 0\n",
    "    df_entry.rename(columns={'time_entry': 'time', 'x_entry': 'x', 'y_entry': 'y'}, inplace=True)\n",
    "    df_exit = df[['hash', 'trajectory_id', 'time_exit', 'x_exit', 'y_exit']].copy()\n",
    "#     df_exit['is_exit'] = 1\n",
    "    df_exit.rename(columns={'time_exit': 'time', 'x_exit': 'x', 'y_exit': 'y'}, inplace=True)\n",
    "\n",
    "    df = pd.concat([df_entry, df_exit], ignore_index=True)\n",
    "\n",
    "#     df['step'] = df['trajectory_id'].apply(lambda x: int(x.split('_')[3]))\n",
    "\n",
    "    df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S')\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['minute'] = df['time'].dt.minute\n",
    "    df['second'] = df['time'].dt.second\n",
    "\n",
    "    df = df.sort_values(['hash', 'time']).reset_index(drop=True)\n",
    "    \n",
    "#     df['distance'] = 0.0\n",
    "#     df['time_delta'] = 0.0\n",
    "#     df['direction'] = 0.0\n",
    "#     # keys = list(enumerate(pd.unique(df['hash'])))\n",
    "\n",
    "#     for device_id in df.hash.unique():\n",
    "#         index_list = df[df['hash'] == device_id].index\n",
    "#         for index in index_list[1:]:\n",
    "#             df.at[index, 'distance'] = np.sqrt((df.at[index, 'x'] - df.at[index - 1, 'x']) ** 2 +\n",
    "#                                                (df.at[index, 'y'] - df.at[index - 1, 'y']) ** 2)\n",
    "#             df.at[index, 'time_delta'] = (df.at[index, 'time'] - df.at[index - 1, 'time']).seconds\n",
    "#             dot = df.at[index, 'x'] * df.at[index - 1, 'x'] + df.at[index, 'y'] * df.at[index - 1, 'y']\n",
    "#             det = df.at[index, 'x'] * df.at[index - 1, 'y'] - df.at[index, 'y'] * df.at[index - 1, 'x']\n",
    "#             df.at[index, 'direction'] = math.degrees(math.atan2(det, dot))\n",
    "    \n",
    "#     df = df.drop(['time'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqNmASztBOIz"
   },
   "outputs": [],
   "source": [
    "df = preprocess(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8m5odp9p9l2E"
   },
   "outputs": [],
   "source": [
    "hash_count = df.groupby('hash').size().reset_index(name='count')\n",
    "# df = df[~df['hash'].isin(hash_count[hash_count['count'] <= 2]['hash'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7xNLhses0LT"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "num_cols = list(df.columns.drop(['hash', 'trajectory_id', 'time']))\n",
    "scaler.fit(df[num_cols])\n",
    "df[num_cols] = scaler.transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ko85dr4MirzR"
   },
   "outputs": [],
   "source": [
    "y = df.sort_values('time').groupby('hash').tail(1).sort_values('hash')\n",
    "X = df[~df.index.isin(y.index)].sort_values(['hash', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3_vaRLX5VOo"
   },
   "outputs": [],
   "source": [
    "group = X.groupby('hash').cumcount()\n",
    "X = (X.drop(['trajectory_id', 'time'], axis=1)\n",
    "      .set_index(['hash', group])\n",
    "      .unstack(fill_value=0)\n",
    "      .stack().groupby(level=0)\n",
    "      .apply(lambda x: x.values.tolist())\n",
    "      .tolist())\n",
    "y = y[['x', 'y']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_seqlen = hash_count.reset_index(drop=True)\n",
    "# full_seqlen = hash_count[hash_count['count'] > 2].reset_index(drop=True)\n",
    "feature_len = len(df.drop(['hash', 'trajectory_id', 'time'], axis=1).columns)\n",
    "max_timestep = max(hash_count['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvR_Ig4zicaH"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(full_seqlen) * 0.8)\n",
    "train_indices = random.sample(range(len(full_seqlen)), train_size)\n",
    "test_indices = list(set(range(len(full_seqlen))) - set(train_indices))\n",
    "\n",
    "X_train = np.asarray([X[i] for i in train_indices])\n",
    "X_test = np.asarray([X[i] for i in test_indices])\n",
    "\n",
    "y_train = np.asarray([y[i] for i in train_indices])\n",
    "y_test = np.asarray([y[i] for i in test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGXk6EWcpLzW"
   },
   "outputs": [],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-QS2yzWCRHZ"
   },
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    for x in range(0, 2):\n",
    "        model.add(Bidirectional(GRU(units=layers[1], input_shape=(None, layers[0]), return_sequences=True)))\n",
    "        model.add(Dropout(rate=0.1))\n",
    "\n",
    "    model.add(Bidirectional(GRU(layers[2], return_sequences=False)))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "\n",
    "    model.add(Dense(units=layers[2]))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['acc', 'mse', 'mae'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDYJUurM7R-7"
   },
   "outputs": [],
   "source": [
    "model = build_model([feature_len, max_timestep, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpWPGyZB7R72",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=200, validation_data=(X_test, y_test), verbose=1, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OO3excRNIJeO"
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6kysCs17R4h"
   },
   "outputs": [],
   "source": [
    "trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Score: %.4f MSE (%.4f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Score: %.4f MSE (%.4f RMSE)' % (testScore[0], math.sqrt(testScore[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHX6V4mI7R1V",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = preprocess(df_test)\n",
    "\n",
    "final_indices = final_df[final_df.isnull().any(axis=1)].index\n",
    "\n",
    "final_df[num_cols] = scaler.transform(final_df[num_cols].fillna(0))\n",
    "\n",
    "final_X = final_df[~final_df.index.isin(final_indices)]\n",
    "\n",
    "final_group = final_X.groupby('hash').cumcount()\n",
    "final_X = (final_X.drop(['trajectory_id', 'time'], axis=1)\n",
    "                  .set_index(['hash', final_group])\n",
    "                  .unstack(fill_value=0)\n",
    "                  .stack().groupby(level=0)\n",
    "                  .apply(lambda x: x.values.tolist())\n",
    "                  .tolist())\n",
    "\n",
    "pred = model.predict(np.asarray(final_X))\n",
    "\n",
    "final_result = final_df[final_df.index.isin(final_indices)][['trajectory_id', 'hour', 'minute', 'second']].reset_index(drop=True).copy()\n",
    "\n",
    "final_result[['x', 'y']] = pd.DataFrame(pred)\n",
    "final_result[num_cols] = scaler.inverse_transform(final_result[num_cols])\n",
    "\n",
    "final_result['target'] = get_target_value(final_result)\n",
    "\n",
    "final_result[['trajectory_id', 'target']].to_csv('submission.csv', header=['id', 'target'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(df['x'], df['y'], c=df['actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nJ39KpYngak"
   },
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71HC1T0LmZUa"
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.drop(['vmax', 'vmin', 'vmean'], axis=1)\n",
    "\n",
    "    df['step'] = df['trajectory_id'].apply(lambda x: int(x.split('_')[3]))\n",
    "\n",
    "    df['time_entry'] = pd.to_datetime(df['time_entry'], format='%H:%M:%S')\n",
    "    df['time_entry_hour'] = df['time_entry'].dt.hour\n",
    "    df['time_entry_minute'] = df['time_entry'].dt.minute\n",
    "    df['time_entry_second'] = df['time_entry'].dt.second\n",
    "    df['time_exit'] = pd.to_datetime(df['time_exit'], format='%H:%M:%S')\n",
    "    df['time_exit_hour'] = df['time_exit'].dt.hour\n",
    "    df['time_exit_minute'] = df['time_exit'].dt.minute\n",
    "    df['time_exit_second'] = df['time_exit'].dt.second\n",
    "\n",
    "    df['time_delta'] = (df['time_exit'] - df['time_entry']).dt.seconds\n",
    "\n",
    "    start_end = df.groupby(['hash']).agg({'step': [np.min, np.max]}).reset_index()\n",
    "    start_end.columns = ['_'.join(tup).rstrip('_') for tup in start_end.columns.values]\n",
    "    df = df.merge(start_end, how='left', on='hash')\n",
    "\n",
    "    for idx in range(len(df)):\n",
    "        if df.at[idx, 'x_entry'] >= X_MIN and df.at[idx, 'x_entry'] <= X_MAX and df.at[idx, 'y_entry'] >= Y_MIN and df.at[idx, 'y_entry'] <= Y_MAX:\n",
    "            df.at[idx, 'entry_in_cc'] = 1\n",
    "        else:\n",
    "            df.at[idx, 'entry_in_cc'] = 0\n",
    "\n",
    "        if df.at[idx, 'step'] == df.at[idx, 'step_amin']:\n",
    "            df.at[idx, 'is_start_point'] = 1\n",
    "            df.at[idx, 'is_end_point'] = 0\n",
    "            df.at[idx, 'is_other_point'] = 0\n",
    "        elif df.at[idx, 'step'] == df.at[idx, 'step_amax']:\n",
    "            df.at[idx, 'is_start_point'] = 0\n",
    "            df.at[idx, 'is_end_point'] = 1\n",
    "            df.at[idx, 'is_other_point'] = 0\n",
    "        else:\n",
    "            df.at[idx, 'is_start_point'] = 0\n",
    "            df.at[idx, 'is_end_point'] = 0\n",
    "            df.at[idx, 'is_other_point'] = 1\n",
    "\n",
    "    features = ['entry_in_cc', 'is_start_point', 'is_end_point', 'is_other_point']\n",
    "    for feature in features:\n",
    "        df[feature] = df[feature].astype('int')\n",
    "\n",
    "    cols_to_drop = ['time_entry', 'time_exit', 'step_amin', 'step_amax']\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    df = df.sort_values(['hash', 'step']).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JAA3uvN8phGZ"
   },
   "outputs": [],
   "source": [
    "df = preprocess(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTRouBKuphDO"
   },
   "outputs": [],
   "source": [
    "hash_count = df.groupby('hash').size().reset_index(name='count')\n",
    "df = df[~df['hash'].isin(hash_count[hash_count['count'] <= 1]['hash'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5R43FdyphAg"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "num_cols = list(df.columns.drop(['hash', 'trajectory_id']))\n",
    "scaler.fit(df[num_cols])\n",
    "df[num_cols] = scaler.transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m56wgxoepg2A"
   },
   "outputs": [],
   "source": [
    "X = df.drop(['x_exit', 'y_exit'], axis=1)\n",
    "y = df[['hash', 'trajectory_id', 'x_exit', 'y_exit']]\n",
    "\n",
    "group = X.groupby('hash').cumcount()\n",
    "X = (X.drop(['trajectory_id'], axis=1)\n",
    "      .set_index(['hash', group])\n",
    "      .unstack(fill_value=0)\n",
    "      .stack().groupby(level=0)\n",
    "      .apply(lambda x: x.values.tolist())\n",
    "      .tolist())\n",
    "y = (y.drop(['trajectory_id'], axis=1)\n",
    "      .set_index(['hash', group])\n",
    "      .unstack(fill_value=0)\n",
    "      .stack().groupby(level=0)\n",
    "      .apply(lambda x: x.values.tolist())\n",
    "      .tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbpI7wdxmz29"
   },
   "outputs": [],
   "source": [
    "full_seqlen = hash_count[hash_count['count'] > 1].reset_index(drop=True)\n",
    "feature_len = len(df.drop(['hash', 'trajectory_id', 'x_exit', 'y_exit'], axis=1).columns)\n",
    "max_timestep = max(hash_count['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZfd2KY3DUxg"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(full_seqlen) * 0.8)\n",
    "train_indices = random.sample(range(len(full_seqlen)), train_size)\n",
    "test_indices = list(set(range(len(full_seqlen))) - set(train_indices))\n",
    "\n",
    "X_train = np.asarray([X[i] for i in train_indices])\n",
    "X_test = np.asarray([X[i] for i in test_indices])\n",
    "\n",
    "y_train = np.asarray([y[i] for i in train_indices])\n",
    "y_test = np.asarray([y[i] for i in test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tWCKAdC6DUr2"
   },
   "outputs": [],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QptG4SFfHYhO"
   },
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    for x in range(0, 3):\n",
    "        model.add(LSTM(return_sequences=True, input_shape=(None, layers[0]), units=layers[1]))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(units=layers[2], input_shape=(None, layers[0])))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy', 'mae'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iILpR51eHYeN"
   },
   "outputs": [],
   "source": [
    "model = build_model([feature_len, max_timestep, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BG8rsmyfHYbT"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtAKq6HyHYYe"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=512, epochs=200, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVBi-l_dHYVw"
   },
   "outputs": [],
   "source": [
    "trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Score: %.4f MSE (%.4f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Score: %.4f MSE (%.4f RMSE)' % (testScore[0], math.sqrt(testScore[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1a3do6LKeEH"
   },
   "outputs": [],
   "source": [
    "final_df = preprocess(df_test)\n",
    "final_df[num_cols] = scaler.transform(final_df[num_cols])\n",
    "\n",
    "final_indices = final_df[final_df.isnull().any(axis=1)].index\n",
    "final_X = final_df[~final_df.index.isin(final_indices)]\n",
    "\n",
    "final_group = final_X.groupby('hash').cumcount()\n",
    "final_X = (final_X.drop(['trajectory_id'], axis=1)\n",
    "                  .set_index(['hash', final_group])\n",
    "                  .unstack(fill_value=0)\n",
    "                  .stack().groupby(level=0)\n",
    "                  .apply(lambda x: x.values.tolist())\n",
    "                  .tolist())\n",
    "\n",
    "pred = model.predict(np.asarray(final_X))\n",
    "\n",
    "final_result = final_df[final_df.index.isin(final_indices)].drop(['x_exit', 'y_exit'], axis=1).reset_index(drop=True).copy()\n",
    "final_result[num_cols] = pd.DataFrame(pred)\n",
    "final_result[num_cols] = scaler.inverse_transform(final_result[num_cols])\n",
    "\n",
    "final_result['target'] = get_target_value(final_result, 'x_exit', 'y_exit')\n",
    "\n",
    "final_result[['trajectory_id', 'target']].to_csv('/tmp/submission.csv', header=['id', 'target'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TkUDePr-tkRf"
   },
   "source": [
    "https://github.com/sheilaalemany/hurricane-rnn/blob/master/hurricane-rnn-sheils.ipynb\n",
    "\n",
    "https://github.com/Oceanland-428/Pedestrian-Trajectories-Prediction-with-RNN/blob/master/read_data.py\n",
    "\n",
    "https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "-nJ39KpYngak"
   ],
   "name": "EY-tf.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
